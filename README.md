# baixing_application

### 2. 有用户反映说他不能访问我们网站，而你是系统工程师，你准备分哪几步来找到问题？ 
  1. 自己用外网ip访问网站，先保证不是全站down掉。分别使用浏览器和命令行（wget/curl）多次访问看是否有问题。可以用其它网络，比如手机3G/4G来访问我们网站，排除外部访问使用的dns服务器down掉或者被污染导致不能正确解析到我们的ip地址。
  2. 查看应用服务器上应用是否正常运行。
    1. 查看服务器的硬件信息和网络状态是否异常。
    2. 查看web服务器日志，有无明显的超时或者拒绝访问等日志。
    3. 如果有明显的超时日志，则根据日志统计超时的url。根据url去分析后端是否异常。比如应用服务器到数据库网络问题、数据库是否有异常、相关应用模块是否近期做过升级而引入慢查询或者存在bug、数据缓存服务是否异常等等。
    4. 如果有拒绝访问日志，则考虑带宽、web服务器并发连接数等是否异常。
  3. 如果前段有负载均衡，检查其有无异常。
  
  以上是首先要保证从我们外网ip入口进来所有后面的系统没有明显异常。
  
  如果可以联系到用户，可以请用户：  
    1. 访问其它网站看是否异常。
    2. 解析我们网站域名，看是否能解析到正确的ip地址。
    3. ping我们网站的ip地址，看是否可以ping通。
    4. 用户通过ip138或者其它途径获取自己的外网ip  
  
  拿到用户ip地址后：  
    1. 在web服务器日志中查找是否收到过来自该ip的访问。如果有且都是正常响应，则使用ping/traceroute等工具排查web服务器到用户ip的网络是否正常，。如果没有，考虑是否是防火墙将用户ip deny掉了。
    2. 也可以使用tcpdump命令获取跟用户ip相关报文进行分析。
  
  如果不能得到用户支持：
    1. 尝试在网上寻找各地和各ISP的代理ip，使用代理ip来访问我们网站，尝试找寻规律。
    2. 如果服务器部署在IDC，跟其确认是否有网络问题。

### 3. 想一想你实现过的一个解决方案，说说它解决了什么问题，有哪些优点、哪些缺点，这样设计的原因是什么，以及对其他人产生了什么样的影响。
目前公司做跨境电商业务，订单信息要经过前台系统（用户下单支付）、后台ERP（审核）、WMS仓储系统、清关事务对接系统、海关系统等众多异构系统。业务人员如果要找一个订单的流转状态，可能要登录不同的系统去查看。  
目前单量也不是很大，提出使用filebeat+logstash+elasticsearch的方案。
  1. 在订单的每一操作点生成统一格式日志写入文件。包括订单号（唯一）、操作人、操作时间、在哪个系统操作、状态变化等。
  2. 在产生日志的服务器上安装filebeat。或将某些服务器日志通过nfs映射到安装有logstash的服务器上。
  3. 三台虚拟机安装elasticsearch做集群。
  4. 开发简单的可视化界面展现订单流转图以及统计。
  5. 通过ldap控制业务人员权限。
  6. 通过elasticsearch的聚合功能结合定时任务实现报警。比如超过3天未出订单、超过30分钟未收到海关接口回执等。

######优点
  1. 快速实现
  2. 对各个系统代码侵入性小
  3. 部署和扩展方便  

######缺点
  1. 代码埋点地方太多
  2. 需要在服务器安装客户端
  3. 写日志会影响性能


### 4. web日志分隔
1. split_log_main.sh为主文件，调用split_log_sub.sh  
  `/bin/bash split_log_main.sh <logfile> <processnum> "Googlebot" "Baiduspider" "^404"`
2. 主要思路  
  1. 先获取log文件第一行和最后一行的日志大小，取平均，然后根据文件大小估算出log文件总行数。使用总行数除以<processnum>得到分隔行数，以此分隔行数使用split将log文件先分隔为近似processnum个小文件；  
  2. 然后调用sub脚本，后台运行，启动脚本进程个数与分隔文件个数相等，脚本中先使用grep过滤，然后使用awk，由于log文件是按照时间排序的，所以只在上下行日期发生变化时计算目标文件日期名称。  
  3. 最后统一对生成的日志进行压缩，多进程后台运行。

